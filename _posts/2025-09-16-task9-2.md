---
title: "[추천시스템] Collaborative Filtering (ALS를 중심으로)"
date: 2025-10-31
categories: [한글, 스터디]
layout: post
tags: [Recommender, 추천시스템, ALS, MatrixFactorization]
permalink: /posts/9-2/
math: true
---

<br>

안녕하세요!  

이번 포스팅은 지난 포스팅에 이어 **협업 필터링** 기반 추천 알고리즘을 알아보도록 하겠습니다.  
코드 실습에는 [Last.fm]('https://www.last.fm/)에서 제공하는 2010년 미국 spotify 데이터를 활용하도록 하겠습니다.  
_note: 용량이 1.5GB 정도로 꽤 크기 때문에 코드만 참고하셔도 좋습니다_

---

### **[협업 필터링(Collaborative Filtering) 이란?]**

지난 포스팅에서도 가볍게 설명했지만, 이번엔 좀 더 자세히 알아보겠습니다.  

고전적 추천 시스템은 크게  

1) 콘텐츠 기반 필터링
2) 협업 필터링  

두 가지로 구분됩니다.  

콘텐츠 기반 필터링이 항목 자체의 특성을 분석하여 추천하는 방식이라면, 
협업 필터링은 **대규모의 기존 사용자 행동 정보**를 분석하고, 해당 사용자와 비슷한 성향의 사용자들에게 항목을 추천하는 방식입니다.  
예를 들어, '라면'을 구입한 사용자가 '생수'를 구입한 경우가 많으면, '라면'을 구입하는 구매자에게 '생수'를 추천하는 형태입니다.  

이러한 알고리즘은 위의 예시처럼 **매우 직관적**이다는 장점이 있으며, 비슷한 패턴을 가진 사용자나 항목을 추출하기 위해 **행렬분해(Matrix Factorization)**, kNN(k-Nearest Neighbor algorithm) 등의 방법이 많이 사용됩니다.  

---

### **[행렬 분해 (Matrix Factorization, MF) 와 CSR(Compressed Sparse Row)]** 


<figure style="text-align: center;">
  <img src="/assets/img/task9-2/mf_before.png" 
       alt="Matrix Factorization" 
       width="80%" 
       style="display: block; margin: auto;">
  <figcaption><em> Matrix before Factorization </em></figcaption>
</figure> 


위 그림은 오늘 실습에서 사용할 spotify 데이터 중 'User - Artist 데이터' 입니다. 협업 필터링 기반 추천 시스템을 만들기 위해서는 **유저 x 아이템** 크기의 행렬이 필요합니다.  

즉,  

- User: 358,868 
- Artist: 291,346  

위처럼 구성된 테이블이 생성되는데요, 약 **1,000억 개**의 값이 생성됩니다. 각 칸에 1 byte 만 할당하더라도 100GB의 메모리가 필요한 크기입니다. 그런데 중요한 사실은, 이 1,000억 개의 데이터 중 대부분은 0 으로 채워져 있다는 점입니다. 아무 의미 없는 0들이 엄청난 메모리를 소모하고 있는 상황인 것이죠.   

그래서 우리는 이러한 희소 행렬(Sparse Matrix)를 효율적으로 저장하기 위해 **CSR(Compressed Sparse Row)** 같은 희소 행렬 저장 방식을 사용합니다. 0은 버리고 실제 상호작용만 저장하여 메모리를 절약하는 방법입니다. 그리고 이러한 CSR 데이터를 기반으로 추천하기 위해 등장한 방법이 바로 **Matrix Factorization(행렬 분해)** 입니다.
_note: CSR 이 데이터를 저장하는 압축 포맷이라면, MF는 이 CSR 데이터를 활용하는 수학적 기법임_


<figure style="text-align: center;">
  <img src="/assets/img/task9-2/mf.png" 
       alt="Matrix Factorization" 
       width="80%" 
       style="display: block; margin: auto;">
  <figcaption><em> Matrix after Factorization </em></figcaption>
</figure> 


Matrix Factorization은 기존의 거대한 행렬에서 **잠재 요인(latent factors)**을 추출하고, 이를 두 개의 벡터(사용자 취향 벡터, 아티스트 특징 벡터)로 분해합니다. 위 예시에서는 100개의 잠재 요인을 설정했기 때문에  

- 사용자 벡터: 358,868 × 100  
- 아티스트 벡터: 291,346 × 100  

두 개의 취향 벡터로 나누어져, 총 약 **6,500만 개**의 값으로 줄어들었습니다. 즉, 기존 데이터의 **0.06%** 메모리만 쓰게 된 것입니다.  

마지막으로 이 두 취향 벡터를 내적(dot)하면 우리가 원하는 `각 사용자의 아티스트별 선호도`를 숫자로서 예측할 수 있게 됩니다.  

---

### **[ALS (Alternating Least Squares) 란?]** 

ALS는 이러한 Matrix Factorization을 효율적으로 학습하는 대표적인 방법입니다. Netflix 에서 주관한 Netflix Prize 에 대회에서 수상한 알고리즘입니다.  

이는 CSR 행렬로부터 잠재 요인을 찾아 user 와 항목(여기선 artist)를 mapping 하여, 두 취향 벡터를 서로 업데이트하는 방식입니다. 간단히 말하자면,  

- User 벡터 고정 > Item 벡터 업데이트    
- Item 벡터 고정 > User 벡터 업데이트    
- 반복..   

의 메커니즘입니다. 


<figure style="text-align: center;">
  <img src="/assets/img/task9-2/ALS.png" 
       alt="ALS" 
       width="80%" 
       style="display: block; margin: auto;">
  <figcaption><em> ALS </em></figcaption>
</figure> 


위 그림처럼 ASL은 User 벡터를 고정한 상태에서 Artist 벡터를 업데이트하고, 이어서 Artist 벡터를 고정한 상태에서 User 벡터를 업데이트합니다. 
이처럼 **교대로 업데이트하며 Loss를 줄이는 것**이 ASL 메커니즘입니다.   
_note: 좀 더 자세히 알아보고 싶다면 [ALS 상세 설명](https://www.youtube.com/watch?v=t3jx3vgKUew)_


---

(작성중..)
